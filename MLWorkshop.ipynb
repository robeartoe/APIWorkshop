{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLWorkshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wkb0z6fP4Yyt",
        "dvHWk_uPLMHs",
        "xz6B0_7iLb7V",
        "8Q9GBB01MOTx",
        "KpFfBugEW6nn"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robeartoe/APIWorkshop/blob/master/MLWorkshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wkb0z6fP4Yyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction to GCP ML API's"
      ]
    },
    {
      "metadata": {
        "id": "RwVJ9yJ9p6s2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-vision\n",
        "!pip install --upgrade google-cloud-speech\n",
        "!pip install --upgrade google-cloud-videointelligence\n",
        "!pip install --upgrade google-cloud-language\n",
        "!pip install --upgrade google-cloud-texttospeech"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyOuwVtfgESB",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "dae95bf5-6c1e-4ead-b789-aa15f9c5cefe"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-053f7f84-950b-4e44-b240-cef3b8dc0ba8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-053f7f84-950b-4e44-b240-cef3b8dc0ba8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving AutoMLWorkshop-620fb45c9b68.json to AutoMLWorkshop-620fb45c9b68.json\n",
            "User uploaded file \"AutoMLWorkshop-620fb45c9b68.json\" with length 2342 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OUmLdnxbtGGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Imports Credential File:\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"AutoMLWorkshop-620fb45c9b68.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZ3PCwNV45kY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloud Vision"
      ]
    },
    {
      "metadata": {
        "id": "dvHWk_uPLMHs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Print Labels:"
      ]
    },
    {
      "metadata": {
        "id": "XoXELKvqQSbR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.elastic.co/assets/bltada7771f270d08f6/enhanced-buzz-1492-1379411828-15.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "Ho30nQiuLMeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cloud Vision:\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "# Instantiates a client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "response = client.annotate_image({\n",
        "   'image': {'source': \n",
        "             {'image_uri': 'https://www.elastic.co/assets/bltada7771f270d08f6/enhanced-buzz-1492-1379411828-15.jpg'}\n",
        "            },\n",
        "})\n",
        "\n",
        "# Detect and Print Labels:\n",
        "labels = response.label_annotations\n",
        "print(\"Labels: \")\n",
        "for label in labels:\n",
        "  print(\"Description: \", label.description, \"Confidence: \", label.score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xz6B0_7iLb7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Detect Landmarks:\n",
        "\n",
        "Documentation : https://cloud.google.com/vision/docs/detecting-landmarks\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bm8Oz9QPLgIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://storage.googleapis.com/automlworkshop-216804-vcm/Bridge.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "pspQWNyEHh8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dac27640-1ed0-42d5-e8d8-0b329e13b4e8"
      },
      "cell_type": "code",
      "source": [
        "# Detect Landmarks:\n",
        "\n",
        "def landmarkDetection(uri):\n",
        "    \"\"\"Detects logos in the file located in Google Cloud Storage or on the Web.\n",
        "    \"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    image = vision.types.Image()\n",
        "    image.source.image_uri = uri\n",
        "\n",
        "    response = client.landmark_detection(image=image)\n",
        "    landmarks = response.landmark_annotations\n",
        "    print('Landmark:')\n",
        "\n",
        "    for landmark in landmarks:\n",
        "        print(landmark.description)\n",
        "        \n",
        "landmarkDetection(\"https://storage.googleapis.com/automlworkshop-216804-vcm/Bridge.jpg\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Landmark:\n",
            "25 de Abril Bridge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTxDb6gFMJf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Detect Logos:"
      ]
    },
    {
      "metadata": {
        "id": "oSXKGnjRRWXq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.gstatic.com/images/branding/product/2x/cloud_512dp.png)"
      ]
    },
    {
      "metadata": {
        "id": "Ya8eY83qH9xS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Detect Logos:\n",
        "# https://cloud.google.com/vision/docs/detecting-logos\n",
        "\n",
        "\n",
        "def detect_logos_uri(uri):\n",
        "    \"\"\"Detects logos in the file located in Google Cloud Storage or on the Web.\n",
        "    \"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    image = vision.types.Image()\n",
        "    image.source.image_uri = uri\n",
        "\n",
        "    response = client.logo_detection(image=image)\n",
        "    logos = response.logo_annotations\n",
        "    print('Logos:')\n",
        "\n",
        "    for logo in logos:\n",
        "        print(logo.description)\n",
        "detect_logos_uri(\"https://www.gstatic.com/images/branding/product/2x/cloud_512dp.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Q9GBB01MOTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Detect Text and Numbers:\n"
      ]
    },
    {
      "metadata": {
        "id": "49ompq7xV78b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://s3.amazonaws.com/production-wordpress-assets/blog/wp-content/uploads/2016/11/29074529/500-internal-server-error.png)"
      ]
    },
    {
      "metadata": {
        "id": "B_jQbTb0MRJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "a03cf752-82ae-449e-c28f-42f61be5f3e0"
      },
      "cell_type": "code",
      "source": [
        "def detect_text_uri(uri):\n",
        "    \"\"\"Detects logos in the file located in Google Cloud Storage or on the Web.\n",
        "    \"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    image = vision.types.Image()\n",
        "    image.source.image_uri = uri\n",
        "\n",
        "    response = client.text_detection(image=image)\n",
        "    texts = response.text_annotations\n",
        "    print('Texts:')\n",
        "\n",
        "    for text in texts:\n",
        "        print(text.description)\n",
        "detect_text_uri(\"https://s3.amazonaws.com/production-wordpress-assets/blog/wp-content/uploads/2016/11/29074529/500-internal-server-error.png\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts:\n",
            "Google\n",
            "500. That's an error.\n",
            "There was an error. Please try again later. That's all we\n",
            "know\n",
            "0\n",
            "\n",
            "Google\n",
            "500.\n",
            "That's\n",
            "an\n",
            "error.\n",
            "There\n",
            "was\n",
            "an\n",
            "error.\n",
            "Please\n",
            "try\n",
            "again\n",
            "later.\n",
            "That's\n",
            "all\n",
            "we\n",
            "know\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KpFfBugEW6nn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Detect Handwritten Text:"
      ]
    },
    {
      "metadata": {
        "id": "iWGYbMqmbgYj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://i.redd.it/7nw3ercwgj011.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "N5z3jNN3W-ZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "3adc0c48-93e9-4609-b9ed-b8266b62ed48"
      },
      "cell_type": "code",
      "source": [
        "def detect_document_uri(uri):\n",
        "    \"\"\"Detects document features in the file located in Google Cloud\n",
        "    Storage.\"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    image = vision.types.Image()\n",
        "    image.source.image_uri = uri\n",
        "    \n",
        "    response = client.document_text_detection(image=image,image_context={'language_hints':'en-t-i0-handwrit'})\n",
        "\n",
        "    for page in response.full_text_annotation.pages:\n",
        "        for block in page.blocks:\n",
        "            print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
        "\n",
        "            for paragraph in block.paragraphs:\n",
        "                print('Paragraph confidence: {}'.format(\n",
        "                    paragraph.confidence))\n",
        "\n",
        "                for word in paragraph.words:\n",
        "                    word_text = ''.join([\n",
        "                        symbol.text for symbol in word.symbols\n",
        "                    ])\n",
        "                    print('Word text: {} (confidence: {})'.format(\n",
        "                        word_text, word.confidence))\n",
        "                    \n",
        "#                     If you want every single symbol in a paragraph:\n",
        "#                     for symbol in word.symbols:\n",
        "#                         print('\\tSymbol: {} (confidence: {})'.format(\n",
        "#                             symbol.text, symbol.confidence))\n",
        "\n",
        "detect_document_uri(\"https://i.redd.it/7nw3ercwgj011.jpg\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Block confidence: 0.9700000286102295\n",
            "\n",
            "Paragraph confidence: 0.9700000286102295\n",
            "Word text: this (confidence: 0.9800000190734863)\n",
            "Word text: is (confidence: 1.0)\n",
            "Word text: my (confidence: 0.9900000095367432)\n",
            "Word text: handwriting (confidence: 0.9599999785423279)\n",
            "Word text: . (confidence: 0.9800000190734863)\n",
            "\n",
            "Block confidence: 0.9200000166893005\n",
            "\n",
            "Paragraph confidence: 0.8899999856948853\n",
            "Word text: this (confidence: 0.8199999928474426)\n",
            "Word text: is (confidence: 0.9800000190734863)\n",
            "Word text: my (confidence: 0.9900000095367432)\n",
            "Word text: handwriting (confidence: 0.8799999952316284)\n",
            "Paragraph confidence: 0.949999988079071\n",
            "Word text: this (confidence: 0.9700000286102295)\n",
            "Word text: is (confidence: 0.9800000190734863)\n",
            "Word text: my (confidence: 0.9800000190734863)\n",
            "Word text: handwriting (confidence: 0.9399999976158142)\n",
            "\n",
            "Block confidence: 0.7599999904632568\n",
            "\n",
            "Paragraph confidence: 0.7599999904632568\n",
            "Word text: 这是我的笔迹 (confidence: 0.7099999785423279)\n",
            "Word text: 。 (confidence: 0.9100000262260437)\n",
            "Word text: 這是我的筆跡 (confidence: 0.7699999809265137)\n",
            "Word text: 。 (confidence: 0.8899999856948853)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TYh4Jwyc4T7N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloud Translate"
      ]
    },
    {
      "metadata": {
        "id": "UNDx7yr99KNT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Translate English to Another Language:"
      ]
    },
    {
      "metadata": {
        "id": "JeVxYFS31-MN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cloud Translate:\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import translate\n",
        "# Instantiates a client\n",
        "translate_client = translate.Client()\n",
        "\n",
        "# The text to translate\n",
        "text = u'Hello World!'\n",
        "# The target language\n",
        "target = 'es'\n",
        "\n",
        "# Translates some text into another language:\n",
        "translation = translate_client.translate(\n",
        "    text,\n",
        "    target_language=target)\n",
        "\n",
        "print(u'Text: {}'.format(text))\n",
        "print(u'Translation: {}'.format(translation['translatedText']))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdNegORq3OXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cloud Translate:\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import translate\n",
        "\n",
        "\"\"\"Lists all available languages.\"\"\"\n",
        "translate_client = translate.Client()\n",
        "\n",
        "results = translate_client.get_languages()\n",
        "\n",
        "for language in results:\n",
        "    print(u'{name} ({language})'.format(**language))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_iy_2VSf9XG0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Detect Language of Incoming Text:"
      ]
    },
    {
      "metadata": {
        "id": "poFEWWOy3k1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "dbcba652-1558-4409-b027-c7ff2a12b9b9"
      },
      "cell_type": "code",
      "source": [
        "# Cloud Translate:\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import translate\n",
        "\n",
        "\"\"\"Detects the text's language.\"\"\"\n",
        "translate_client = translate.Client()\n",
        "\n",
        "# The text to detect:\n",
        "text = u'Muchas Gracias!'\n",
        "\n",
        "# Text can also be a sequence of strings, in which case this method\n",
        "# will return a sequence of results for each text.\n",
        "result = translate_client.detect_language(text)\n",
        "\n",
        "print('Text: {}'.format(text))\n",
        "print('Confidence: {}'.format(result['confidence']))\n",
        "print('Language: {}'.format(result['language']))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: Muchas Gracias!\n",
            "Confidence: 1\n",
            "Language: es\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4EwVa0IR9CnI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://sagedandconfused.files.wordpress.com/2013/12/tumblr_mh9rzpg2se1qd6sqao1_400.png)"
      ]
    },
    {
      "metadata": {
        "id": "6vtklfg64b4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloud Natural Language"
      ]
    },
    {
      "metadata": {
        "id": "9KI2ZdxT4btS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c24da7bc-850a-4920-add7-2189bf7b5712"
      },
      "cell_type": "code",
      "source": [
        "# Imports the Google Cloud client library\n",
        "from google.cloud import language\n",
        "from google.cloud.language import enums\n",
        "from google.cloud.language import types\n",
        "\n",
        "# Instantiates a client\n",
        "client = language.LanguageServiceClient()\n",
        "\n",
        "# The text to analyze\n",
        "text = u'Whatever you want, I don\\'t care.'\n",
        "document = types.Document(\n",
        "    content=text,\n",
        "    type=enums.Document.Type.PLAIN_TEXT)\n",
        "\n",
        "# Detects the sentiment of the text\n",
        "sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
        "\n",
        "print('Text: {}'.format(text))\n",
        "print('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: Whatever you want, I don't care.\n",
            "Sentiment: -0.30000001192092896, 0.30000001192092896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aP-7RvBJL6N_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloud Text to Speech"
      ]
    },
    {
      "metadata": {
        "id": "EGglyw7NeamO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.cloud import texttospeech\n",
        "\n",
        "# Instantiates a client\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "# Set the text input to be synthesized\n",
        "synthesis_input = texttospeech.types.SynthesisInput(text=\"Hello, World!\")\n",
        "\n",
        "# Build the voice request, select the language code (\"en-US\") and the ssml\n",
        "# voice gender (\"neutral\")\n",
        "voice = texttospeech.types.VoiceSelectionParams(\n",
        "    language_code='en-US',\n",
        "    ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL)\n",
        "\n",
        "# Select the type of audio file you want returned\n",
        "audio_config = texttospeech.types.AudioConfig(\n",
        "    audio_encoding=texttospeech.enums.AudioEncoding.LINEAR16)\n",
        "\n",
        "# Perform the text-to-speech request on the text input with the selected\n",
        "# voice parameters and audio file type\n",
        "response = client.synthesize_speech(synthesis_input, voice, audio_config)\n",
        "\n",
        "# The response's audio_content is binary.\n",
        "with open('output.wav', 'wb') as out:\n",
        "    # Write the response to the output file.\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"output.wav\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGMQvRC97Eqf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloud Speech to Text"
      ]
    },
    {
      "metadata": {
        "id": "Snq8ehAu7JkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import speech\n",
        "from google.cloud.speech import enums\n",
        "from google.cloud.speech import types\n",
        "\n",
        "# Instantiates a client\n",
        "client = speech.SpeechClient()\n",
        "\n",
        "# The name of the audio file to transcribe\n",
        "file_name = 'output.wav'\n",
        "\n",
        "# Loads the audio into memory\n",
        "with io.open(file_name, 'rb') as audio_file:\n",
        "    content = audio_file.read()\n",
        "    audio = types.RecognitionAudio(content=content)\n",
        "\n",
        "config = types.RecognitionConfig(\n",
        "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "    language_code='en-US')\n",
        "\n",
        "# Detects speech in the audio file\n",
        "response = client.recognize(config, audio)\n",
        "\n",
        "\n",
        "for result in response.results:\n",
        "    print('Transcript: {}'.format(result.alternatives[0].transcript))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}